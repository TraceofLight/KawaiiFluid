// Copyright 2026 Team_Bruteforce. All Rights Reserved.
/**
 * @file KawaiiFluidRadixSort.usf
 * @brief Shader implementation for KawaiiFluidRadixSort
 */

// GPU Fluid Physics - Radix Sort for Morton Code Sorting
//
// Implements parallel radix sort on GPU for sorting particles by Morton code.
// Uses 8-bit radix (256 buckets) with 3 passes for 21-bit Morton codes (24-bit coverage).
//
// Pipeline:
// 1. Histogram: Each thread group computes per-warp histogram
// 2. Global Prefix Sum: Compute global offsets for each Bucket
// 3. Scatter: Write elements to final positions (STABLE via Wave Intrinsics ranking)
//
// OPTIMIZATIONS:
// - 8-bit radix reduces passes from 6 to 3, halving dispatch overhead
// - Wave Intrinsics for O(1) intra-warp ranking (replaces O(128) LDS scan)
// - Wave-level histogram reduces LDS atomic contention
//
// NOTE: Wave Intrinsics are SAFE here because:
// - All threads execute same number of iterations ([unroll] loops)
// - No early returns - all threads complete together
// - No divergent control flow within warp
//
// LDS Usage: ~9KB (Warp histogram 8KB + Base offsets 1KB)

#include "/Engine/Public/Platform.ush"
#include "/Engine/Private/Common.ush"

//=============================================================================
// Wave Intrinsics Support Detection
// SM6.0+ required for Wave Intrinsics (WaveActiveBallot, WaveGetLaneIndex, etc.)
// If platform doesn't define this macro, assume NOT supported (safe fallback)
//=============================================================================
#ifndef COMPILER_SUPPORTS_WAVE_INTRINSICS
    #define COMPILER_SUPPORTS_WAVE_INTRINSICS 0   // Default: LDS fallback (safe for all platforms)
#endif

//=============================================================================
// Configuration - 8-bit Radix (256 buckets)
//=============================================================================

#define RADIX_BITS 8                    // 8 bits per PassIndex (256 buckets)
#define RADIX_SIZE (1 << RADIX_BITS)    // 256 buckets
#define RADIX_MASK (RADIX_SIZE - 1)     // 0xFF

#define THREAD_GROUP_SIZE 256
#define ELEMENTS_PER_THREAD 4           // Each thread processes 4 elements
#define ELEMENTS_PER_GROUP (THREAD_GROUP_SIZE * ELEMENTS_PER_THREAD)  // 1024

#define WARP_SIZE 32
#define NUM_WARPS (THREAD_GROUP_SIZE / WARP_SIZE)  // 8 warps

//=============================================================================
// Shader Parameters
//=============================================================================

// Input buffers (read-only, bound as SRV)
StructuredBuffer<uint> KeysIn;
StructuredBuffer<uint> ValuesIn;

// Output buffers (write, bound as UAV)
RWStructuredBuffer<uint> KeysOut;
RWStructuredBuffer<uint> ValuesOut;

// Histogram and prefix Sum buffers
// Note: These have both RW and RO versions for different shader passes
RWStructuredBuffer<uint> Histogram;      // [NumGroups * RADIX_SIZE] - UAV for Histogram/PrefixSum passes
RWStructuredBuffer<uint> GlobalOffsets;  // [RADIX_SIZE] - UAV for PrefixSum passes

// Read-only versions for Scatter PassIndex (bound as SRV)
StructuredBuffer<uint> HistogramSRV;
StructuredBuffer<uint> GlobalOffsetsSRV;

int ElementCount;
int BitOffset;       // Current bit position (0, 8, 16 for 8-bit radix)
int NumGroups;       // Number of thread groups

//=============================================================================
// Shared Memory for Histogram Pass
//=============================================================================

groupshared uint LocalHistogram[RADIX_SIZE];                 // 1KB - per-group histogram

//=============================================================================
// Pass 1: Histogram Computation (8-bit radix)
// Each thread group counts elements per Bucket using warp-level atomics
//=============================================================================

/**
 * @brief Compute shader entry point for RadixSortHistogramCS
 */
[numthreads(THREAD_GROUP_SIZE, 1, 1)]
void RadixSortHistogramCS(
    uint3 GroupId : SV_GroupID,
    uint3 GroupThreadId : SV_GroupThreadID,
    uint3 DispatchThreadId : SV_DispatchThreadID)
{
    uint LocalIdx = GroupThreadId.x;
    uint GroupIdx = GroupId.x;
    uint GlobalBase = GroupIdx * ELEMENTS_PER_GROUP;

    // Initialize local histogram (256 threads clear 256 buckets - perfect 1:1)
    LocalHistogram[LocalIdx] = 0;
    GroupMemoryBarrierWithGroupSync();

    // Load elements and Count (only valid elements)
    [unroll]
    for (uint i = 0; i < ELEMENTS_PER_THREAD; ++i)
    {
        uint ElementIdx = GlobalBase + LocalIdx * ELEMENTS_PER_THREAD + i;

        if (ElementIdx < (uint)ElementCount)
        {
            uint Key = KeysIn[ElementIdx];
            uint Digit = (Key >> BitOffset) & RADIX_MASK;
            InterlockedAdd(LocalHistogram[Digit], 1);
        }
    }
    GroupMemoryBarrierWithGroupSync();

    // Write histogram to global memory (256 threads write 256 values - coalesced)
    Histogram[GroupIdx * RADIX_SIZE + LocalIdx] = LocalHistogram[LocalIdx];
}

//=============================================================================
// Pass 2: Global Prefix Sum over Histograms
// Computes global offsets for each Bucket across all groups
// 256 threads process 256 buckets in parallel
//=============================================================================

/**
 * @brief Compute shader entry point for RadixSortGlobalPrefixSumCS
 */
[numthreads(RADIX_SIZE, 1, 1)]
void RadixSortGlobalPrefixSumCS(uint3 DispatchThreadId : SV_DispatchThreadID)
{
    uint BucketIdx = DispatchThreadId.x;
    if (BucketIdx >= RADIX_SIZE)
    {
        return;
    }

    // Sum counts for this Bucket across all groups
    uint TotalCount = 0;
    for (int g = 0; g < NumGroups; ++g)
    {
        uint Count = Histogram[g * RADIX_SIZE + BucketIdx];
        Histogram[g * RADIX_SIZE + BucketIdx] = TotalCount;  // Store prefix for this group
        TotalCount += Count;
    }

    // Store total Count in global offsets (will be prefix-summed next)
    GlobalOffsets[BucketIdx] = TotalCount;
}

//=============================================================================
// Pass 2b: Prefix Sum over Global Offsets
// Converts Bucket totals to Bucket start positions
//
// Wave-optimized: O(log n) parallel prefix Sum using WavePrefixSum
// Fallback: O(n) sequential prefix Sum
//
// Both versions dispatch with (1, 1, 1) groups - thread Count differs in numthreads
//=============================================================================

#if COMPILER_SUPPORTS_WAVE_INTRINSICS

// Wave-optimized version: 256 threads with WavePrefixSum + LDS cross-wave
// Complexity: O(log WaveSize) intra-wave + O(numWaves) cross-wave
groupshared uint BucketWaveTotals[8];  // Max 8 waves (256 threads / 32 wave size)

/**
 * @brief Compute shader entry point for RadixSortBucketPrefixSumCS
 */
[numthreads(RADIX_SIZE, 1, 1)]
void RadixSortBucketPrefixSumCS(uint3 GroupThreadId : SV_GroupThreadID)
{
    uint Idx = GroupThreadId.x;
    uint LaneIdx = WaveGetLaneIndex();
    uint WaveSize = WaveGetLaneCount();
    uint WaveIdx = Idx / WaveSize;

    // Step 1: Read Bucket Count
    uint MyCount = GlobalOffsets[Idx];

    // Step 2: Intra-wave exclusive prefix Sum (O(log WaveSize) internally)
    uint WavePrefixValue = WavePrefixSum(MyCount);
    uint WaveTotal = WaveActiveSum(MyCount);

    // Step 3: First lane of each wave stores wave total to LDS
    if (WaveIsFirstLane())
    {
        BucketWaveTotals[WaveIdx] = WaveTotal;
    }
    GroupMemoryBarrierWithGroupSync();

    // Step 4: Compute cross-wave prefix (small sequential loop, max 8 iterations)
    uint CrossWavePrefix = 0;
    for (uint w = 0; w < WaveIdx; ++w)
    {
        CrossWavePrefix += BucketWaveTotals[w];
    }

    // Step 5: Final prefix = cross-wave prefix + intra-wave prefix
    GlobalOffsets[Idx] = CrossWavePrefix + WavePrefixValue;
}

#else

/**
 * @brief Compute shader entry point for RadixSortBucketPrefixSumCS
 * Complexity: O(n) where n = RADIX_SIZE (256)
 */
[numthreads(1, 1, 1)]
void RadixSortBucketPrefixSumCS(uint3 DispatchThreadId : SV_DispatchThreadID)
{
    uint PrefixSum = 0;
    for (uint i = 0; i < RADIX_SIZE; ++i)
    {
        uint Count = GlobalOffsets[i];
        GlobalOffsets[i] = PrefixSum;
        PrefixSum += Count;
    }
}

#endif

//=============================================================================
// Pass 3: Scatter Elements to Final Positions (STABLE SORT)
//
// 8-bit Radix with Warp-level Histogram + LDS-based Stable Ranking
//
// Algorithm:
// 1. Load elements and store digits to LDS for stable ranking
// 2. Build per-warp histogram using atomics (just counting)
// 3. Compute per-warp prefix sums (deterministic)
// 4. Scatter with LDS-based intra-warp ranking (STABLE)
//
// LDS Usage:
// - WarpBucketData[8 * 256] = 8KB (warp histogram + prefix sums)
// - DigitBaseOffsets[256] = 1KB (global + group offsets)
// - ElementDigits[1024] = 4KB (for stable intra-warp ranking)
// Total: 13KB (fits in 32KB LDS limit)
//=============================================================================

groupshared uint WarpBucketData[NUM_WARPS * RADIX_SIZE];  // 8KB
groupshared uint DigitBaseOffsets[RADIX_SIZE];            // 1KB
groupshared uint ElementDigits[ELEMENTS_PER_GROUP];       // 4KB

/**
 * @brief Compute shader entry point for RadixSortScatterCS
 */
[numthreads(THREAD_GROUP_SIZE, 1, 1)]
void RadixSortScatterCS(
    uint3 GroupId : SV_GroupID,
    uint3 GroupThreadId : SV_GroupThreadID)
{
    uint LocalIdx = GroupThreadId.x;
    uint GroupIdx = GroupId.x;
    uint GlobalBase = GroupIdx * ELEMENTS_PER_GROUP;
    uint WarpId = LocalIdx / WARP_SIZE;

    //=========================================================================
    // Step 1: Load elements and store digits to LDS
    //=========================================================================

    uint MyKeys[ELEMENTS_PER_THREAD];
    uint MyValues[ELEMENTS_PER_THREAD];
    uint MyDigits[ELEMENTS_PER_THREAD];
    uint MyValid[ELEMENTS_PER_THREAD];

    [unroll]
    for (uint i = 0; i < ELEMENTS_PER_THREAD; ++i)
    {
        uint ElementIdx = GlobalBase + LocalIdx * ELEMENTS_PER_THREAD + i;
        uint LocalElementIdx = LocalIdx * ELEMENTS_PER_THREAD + i;

        if (ElementIdx < (uint)ElementCount)
        {
            MyKeys[i] = KeysIn[ElementIdx];
            MyValues[i] = ValuesIn[ElementIdx];
            MyDigits[i] = (MyKeys[i] >> BitOffset) & RADIX_MASK;
            MyValid[i] = 1;
            ElementDigits[LocalElementIdx] = MyDigits[i];
        }
        else
        {
            MyKeys[i] = 0xFFFFFFFF;
            MyValues[i] = 0;
            MyDigits[i] = 0xFF;
            MyValid[i] = 0;
            ElementDigits[LocalElementIdx] = 0xFFFFFFFF;  // Invalid marker
        }
    }

    //=========================================================================
    // Step 2: Clear and build per-warp histograms
    //=========================================================================

    // Clear warp Bucket data (256 threads clear 8*256=2048 values)
    for (uint b = LocalIdx; b < NUM_WARPS * RADIX_SIZE; b += THREAD_GROUP_SIZE)
    {
        WarpBucketData[b] = 0;
    }
    GroupMemoryBarrierWithGroupSync();

    // Count elements per warp per Bucket (atomics for counting only)
    [unroll]
    for (uint i = 0; i < ELEMENTS_PER_THREAD; ++i)
    {
        if (MyValid[i])
        {
            InterlockedAdd(WarpBucketData[WarpId * RADIX_SIZE + MyDigits[i]], 1);
        }
    }
    GroupMemoryBarrierWithGroupSync();

    //=========================================================================
    // Step 3: Load global offsets and compute per-warp prefix sums
    // 256 threads handle 256 buckets in parallel
    //=========================================================================

    {
        uint Bucket = LocalIdx;
        DigitBaseOffsets[Bucket] = GlobalOffsetsSRV[Bucket] + HistogramSRV[GroupIdx * RADIX_SIZE + Bucket];

        // Prefix Sum across warps for this Bucket (8 iterations, sequential)
        uint Sum = 0;
        for (uint w = 0; w < NUM_WARPS; ++w)
        {
            uint Idx = w * RADIX_SIZE + Bucket;
            uint Count = WarpBucketData[Idx];
            WarpBucketData[Idx] = Sum;  // Replace Count with prefix
            Sum += Count;
        }
    }
    GroupMemoryBarrierWithGroupSync();

    //=========================================================================
    // Step 4: Scatter with STABLE intra-warp ranking
    //
    // For stability: rank = Count of elements with same Digit that come
    // BEFORE this element in deterministic order (thread 0 elem 0 first,
    // then thread 0 elem 1, ..., thread 31 elem 3).
    //
    // This scan is O(128) per element but guarantees deterministic ordering.
    //=========================================================================

    uint WarpStartElement = WarpId * (WARP_SIZE * ELEMENTS_PER_THREAD);  // 128 elements per warp

    [unroll]
    for (uint i = 0; i < ELEMENTS_PER_THREAD; ++i)
    {
        if (MyValid[i])
        {
            uint Digit = MyDigits[i];
            uint MyElementIdx = LocalIdx * ELEMENTS_PER_THREAD + i;
            uint MyWarpLocalIdx = MyElementIdx - WarpStartElement;

            // Count elements with same Digit before this one within the warp
            // This is the Key to STABLE sort - deterministic ordering
            uint RankInWarp = 0;
            for (uint j = 0; j < MyWarpLocalIdx; ++j)
            {
                if (ElementDigits[WarpStartElement + j] == Digit)
                {
                    RankInWarp++;
                }
            }

            // Final output position:
            // Global Bucket start + warp's prefix within group + rank within warp
            uint OutputPos = DigitBaseOffsets[Digit]
                           + WarpBucketData[WarpId * RADIX_SIZE + Digit]
                           + RankInWarp;

            KeysOut[OutputPos] = MyKeys[i];
            ValuesOut[OutputPos] = MyValues[i];
        }
    }
}

//=============================================================================
// Simple Single-Pass Sort for Small Arrays (< 1024 elements)
// Uses shared memory for complete sort within one group
// Note: Uses counting sort with atomics - not stable but correct for Morton sorting
//
// Shared memory usage: ~20KB (well under 32KB limit)
//=============================================================================

#define SMALL_SORT_THREAD_COUNT 256
#define SMALL_SORT_ELEMENTS_PER_THREAD 4

groupshared uint SmallSortKeys[1024];      // 4KB
groupshared uint SmallSortValues[1024];    // 4KB
groupshared uint SmallSortTemp[1024];      // 4KB
groupshared uint SmallSortTempV[1024];     // 4KB
groupshared uint SmallHistogram[RADIX_SIZE];        // 1KB
groupshared uint SmallPrefixSum[RADIX_SIZE];        // 1KB
#if COMPILER_SUPPORTS_WAVE_INTRINSICS
groupshared uint SmallWaveTotals[8];       // 32B - wave totals for parallel prefix Sum
#endif

/**
 * @brief Compute shader entry point for RadixSortSmallCS
 */
[numthreads(SMALL_SORT_THREAD_COUNT, 1, 1)]
void RadixSortSmallCS(uint3 GroupThreadId : SV_GroupThreadID)
{
    uint LocalIdx = GroupThreadId.x;
    uint ElemIdx, LoopIdx;

    // Load data to shared memory
    [unroll]
    for (LoopIdx = 0; LoopIdx < SMALL_SORT_ELEMENTS_PER_THREAD; ++LoopIdx)
    {
        ElemIdx = LocalIdx * SMALL_SORT_ELEMENTS_PER_THREAD + LoopIdx;
        if (ElemIdx < (uint)ElementCount)
        {
            SmallSortKeys[ElemIdx] = KeysIn[ElemIdx];
            SmallSortValues[ElemIdx] = ValuesIn[ElemIdx];
        }
        else
        {
            SmallSortKeys[ElemIdx] = 0xFFFFFFFF;  // Max Value for padding
            SmallSortValues[ElemIdx] = 0;
        }
    }
    GroupMemoryBarrierWithGroupSync();

    // Perform 3 passes of 8-bit radix sort in shared memory (24-bit keys)
    for (int PassIndex = 0; PassIndex < 3; ++PassIndex)
    {
        int BitOffsetLocal = PassIndex * 8;

        //=====================================================================
        // Step 1: Clear histogram
        //=====================================================================
        if (LocalIdx < RADIX_SIZE)
        {
            SmallHistogram[LocalIdx] = 0;
        }
        GroupMemoryBarrierWithGroupSync();

        //=====================================================================
        // Step 2: Build histogram (only Count valid elements)
        //=====================================================================
        [unroll]
        for (LoopIdx = 0; LoopIdx < SMALL_SORT_ELEMENTS_PER_THREAD; ++LoopIdx)
        {
            ElemIdx = LocalIdx * SMALL_SORT_ELEMENTS_PER_THREAD + LoopIdx;
            if (ElemIdx < (uint)ElementCount)
            {
                uint Digit = (SmallSortKeys[ElemIdx] >> BitOffsetLocal) & RADIX_MASK;
                InterlockedAdd(SmallHistogram[Digit], 1);
            }
        }
        GroupMemoryBarrierWithGroupSync();

        //=====================================================================
        // Step 3: Exclusive prefix Sum on histogram (256 buckets)
        // Wave path: O(log n) parallel using WavePrefixSum + LDS
        // Fallback: O(n) sequential single-thread
        //=====================================================================
#if COMPILER_SUPPORTS_WAVE_INTRINSICS
        {
            // All 256 threads participate in parallel prefix Sum
            uint LaneIdx = WaveGetLaneIndex();
            uint WaveSize = WaveGetLaneCount();
            uint WaveIdx = LocalIdx / WaveSize;

            uint MyCount = SmallHistogram[LocalIdx];
            uint WavePrefixValue = WavePrefixSum(MyCount);
            uint WaveTotal = WaveActiveSum(MyCount);

            if (WaveIsFirstLane())
            {
                SmallWaveTotals[WaveIdx] = WaveTotal;
            }
            GroupMemoryBarrierWithGroupSync();

            uint CrossWavePrefix = 0;
            for (uint w = 0; w < WaveIdx; ++w)
            {
                CrossWavePrefix += SmallWaveTotals[w];
            }

            SmallPrefixSum[LocalIdx] = CrossWavePrefix + WavePrefixValue;
        }
        GroupMemoryBarrierWithGroupSync();
#else
        if (LocalIdx == 0)
        {
            uint Sum = 0;
            for (uint b = 0; b < RADIX_SIZE; ++b)
            {
                uint Count = SmallHistogram[b];
                SmallPrefixSum[b] = Sum;
                Sum += Count;
            }
        }
        GroupMemoryBarrierWithGroupSync();
#endif

        //=====================================================================
        // Step 4: Scatter to temp buffer using atomic increment
        //=====================================================================
        [unroll]
        for (LoopIdx = 0; LoopIdx < SMALL_SORT_ELEMENTS_PER_THREAD; ++LoopIdx)
        {
            ElemIdx = LocalIdx * SMALL_SORT_ELEMENTS_PER_THREAD + LoopIdx;
            if (ElemIdx < (uint)ElementCount)
            {
                uint Key = SmallSortKeys[ElemIdx];
                uint Value = SmallSortValues[ElemIdx];
                uint Digit = (Key >> BitOffsetLocal) & RADIX_MASK;

                uint OutPos;
                InterlockedAdd(SmallPrefixSum[Digit], 1, OutPos);

                SmallSortTemp[OutPos] = Key;
                SmallSortTempV[OutPos] = Value;
            }
        }
        GroupMemoryBarrierWithGroupSync();

        //=====================================================================
        // Step 5: Copy back from temp to main arrays
        //=====================================================================
        [unroll]
        for (LoopIdx = 0; LoopIdx < SMALL_SORT_ELEMENTS_PER_THREAD; ++LoopIdx)
        {
            ElemIdx = LocalIdx * SMALL_SORT_ELEMENTS_PER_THREAD + LoopIdx;
            SmallSortKeys[ElemIdx] = SmallSortTemp[ElemIdx];
            SmallSortValues[ElemIdx] = SmallSortTempV[ElemIdx];
        }
        GroupMemoryBarrierWithGroupSync();
    }

    // Write results to output
    [unroll]
    for (LoopIdx = 0; LoopIdx < SMALL_SORT_ELEMENTS_PER_THREAD; ++LoopIdx)
    {
        ElemIdx = LocalIdx * SMALL_SORT_ELEMENTS_PER_THREAD + LoopIdx;
        if (ElemIdx < (uint)ElementCount)
        {
            KeysOut[ElemIdx] = SmallSortKeys[ElemIdx];
            ValuesOut[ElemIdx] = SmallSortValues[ElemIdx];
        }
    }
}

